{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o4u3lgiYwCe6"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (AutoTokenizer, AutoConfig,\n",
    "    AutoModelForSequenceClassification, Trainer, TrainingArguments,\n",
    "    DataCollatorWithPadding)\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237,
     "referenced_widgets": [
      "e8c672b415e14f4a8cba7f96d1728f6c",
      "78ddb2ec2f4846279c9ac787061a61f7",
      "da9b3eeff2ec49e68c5c871bd832a418",
      "c8553f8d901446af8b11054d9d68877a",
      "364b03fd0ee5403dbdea2bab527071f7",
      "fe167dc5b022451aac8ace255bdecbe7",
      "49b4ba7a96c04499a40a4d1cdf281ca6",
      "bdafe21423ff4dbeb620043c341a794c",
      "807106adb58347e4a285ac44a2ce6247",
      "a7996ead986745b7b8ad6bed4fac9b80",
      "638bf10d82454f9f9dcc87052d5b9066",
      "355e916e140a41e0b1a88ef4681cf37e",
      "7d4556dc49884e4db284b087075ab7cb",
      "34cc6cdc44af4baaa331f0e9e23c12b1",
      "635c122d564647739c1788abccd2d4f2",
      "a4a5d6659e824fd59e07c3a69415998d",
      "089704d735194392bd594717f558dc00",
      "561fbaeddf02414c997f8b585465ab54",
      "5f9bf7765f764b63a5b9c227cd1113ed",
      "cd3b4e3dba11454c93e18ae18cb91d38",
      "979c0d4f642c4e549bbbc59255189d91",
      "1aaab3688cea4f6689058b99edca5597"
     ]
    },
    "id": "jPtbK9QNwESB",
    "outputId": "f9cb6cda-a9a0-4f78-d3b7-f797b7e15377"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c672b415e14f4a8cba7f96d1728f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355e916e140a41e0b1a88ef4681cf37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "id2label = {0: 'Negative', 1: 'Positive'}\n",
    "label2id = {'Negative': 0, 'Positive': 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels = 2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347,
     "referenced_widgets": [
      "f0bfcaa6fffa4335ac95ea3a5bf043c8",
      "a82011a75e864a769b30d7d0d73f3a28",
      "81b8645da2c34b5babea5047a518a5b9",
      "486d3e2162a74bb78536df83db58cde1",
      "44c8e102fe694a8c9f1cab5ff5db4582",
      "439fcf13d79641bd9a2c959b3ef09dab",
      "097edce55daa4b288c52d09f0e6704e7",
      "b386babb964d47e58582d50a8c4d6e4d",
      "3e180c3fd52d45f2945f30e18b5e7000",
      "b6c2b33ab1e9489581c9c7793001da54",
      "3c949173e1c04a5182e44a69514e1f01",
      "21d974558ca34b9cbb999365b6565b6e",
      "c2cc401dc1d542deae9f0017fe3632c8",
      "711ba826cac94a3c8b24a9d1b405e69b",
      "50a8160dc1af44f3b6a5314378a76a02",
      "55acaaa70d7e49c28d1396e299fea86e",
      "12e7a8adb01f45dbb729d13fcffae0e2",
      "1fc281665ce74963a5118c42351f9ad0",
      "5d47b62213f24c91a9a78c91413649b3",
      "9da2d43cbbb04732913d0646530fcdcb",
      "ff0ef008b2424166b03de79cd9e4684e",
      "765f7362e09545fcbafdeb425fb20768",
      "0076b09448db43cfbe1f3d8df2795e65",
      "df623334c1ef415ea47081d246522f19",
      "c0cec817cd704b10866cad5c772a8516",
      "ebcdf230a94d493da764d97f5ac68459",
      "3bcbf1080d6c4bb8a31738d5c2db1746",
      "3de54df6eb884bc7b7db22fc2a71f963",
      "2105d159ccd74d09bab21456b3a899c1",
      "fd838333af3e4bc8a613d105035ac344",
      "7b81795353c44999a786cd78de005a72",
      "12e6accb50b0437aa289952dd43f231c",
      "0d70143bc17f46a0aeac7f9d35efa51b",
      "7deb2cba68154d0bbdebf9adf06e600d",
      "12b6381f8bba4adbba5cb9b97d6c3f94",
      "e9e8adfc3b6b41a5b4406d7184a24470",
      "ed8a8ea10cb74afeb857d6169f93b918",
      "dd4456de224546fd945bbde68835bc10",
      "d830e90db2dc4d019158fccb33cca573",
      "127a75dd877c4503b5366f072ae5a6b4",
      "4d269cbebec1463aa4fc9df057b48299",
      "6c0f208fd15347b6a2aeb6e0548ae0c6",
      "be7dac91bb3f4322af78045aa62eb071",
      "6c28f72df4944c819eecf3d14bc8b4e8",
      "cce2afac51ae4c1db6def5c410272df6",
      "36df41f587714250a67949af43c7755f",
      "56d76807170b4fada2675858b5ea2656",
      "6193044ca3e640c891d124ee631b8527",
      "2a539b2b9563438180728a60b077087a",
      "78714ea225834b7aa2bb9474bf93674f",
      "10e3a0405a9d45aabf7312af02c6047f",
      "b1baa92c2c6a479b9a8f28f303f1cc0f",
      "57c3051e85ba46998b9caedaa3d39ac3",
      "92eb9575faf14ecea5887d3cda4ef3e3",
      "7a94b60e81744dc887c8326bd65a13f1"
     ]
    },
    "id": "PzcCGt1gwMpI",
    "outputId": "5dc7d7a7-e534-4901-ce14-0c30ace9092c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bfcaa6fffa4335ac95ea3a5bf043c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d974558ca34b9cbb999365b6565b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-5a744bf76a1d84b2.parquet:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0076b09448db43cfbe1f3d8df2795e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-a3a52fabb70c739f.parquet:   0%|          | 0.00/853k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb2cba68154d0bbdebf9adf06e600d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce2afac51ae4c1db6def5c410272df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"shawhin/imdb-truncated\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347,
     "referenced_widgets": [
      "5a249604a45643c0b76b113d9e1c4a1a",
      "b02c7b1167e74fb4a46cbc66b1f1d844",
      "6a02144691aa4c8d8ecbd1a1d8860058",
      "c82f2659f22b4ef4bda1aea6f05d0128",
      "e7011915d5f046feae807fa1dd33628d",
      "e3a6f22a450a421182b3af0727b1c1e7",
      "ef57440a08834e0ca55593cce971e831",
      "31e36322b0f04db4a76ea4eedad28256",
      "af8adc7018774d87a9e05536b362a00f",
      "f20a3ccbd49b432d983c201e19f661de",
      "01f59c21ff0b497da7794e9786fb7e30",
      "a0a33d73668c4a4f853c24dca53090d9",
      "cd1406bc358e4fd4987e362fe7d32521",
      "0c7838e9edd34b139d899c13698d2599",
      "5b389c588c974383b0556f339bbf2178",
      "dca8f995e1b94785a66b226458691c98",
      "403b20c18b074160a50800aded19d0b7",
      "a2445bcd8f8c4735a4068886e9ed61d8",
      "b3b41bc8e7344f7d8297aeaec30f5c9c",
      "26fa32ebcceb4227a938e1f1671b50e0",
      "e333b4db512540948d5e3bba5d76e5e2",
      "f962d8ca064245bda204eb5b5f802a53",
      "00a4e979bc1e4186bd19c0ef868662c4",
      "f4ee804416c3464aa6dadc1038ba54c9",
      "809c396ddbf84b02addc5da213680d5c",
      "3e6b43626b2b44438946bf84b7216e70",
      "7635a812f25148279d4ffcbb8ca910fc",
      "64ebac84a5ca4b80a4f061fb4bae9bf7",
      "194c996f01c847b8a245a8cca25883ca",
      "a1f1e868588f44b4b55309089318cf2c",
      "112f4fafbe864813b0e7176eb34023d0",
      "2899e1d1d1b84a06b30812378bd89dfc",
      "a099df2c9c1545d1b344a8399f7452f6",
      "8c8c6f823c474a1a852d17a8a523630f",
      "e3bef8dcc2634b669d87e20ca101f786",
      "14524246ad0942ce9d81fc3f2288e134",
      "8bdcfab1be294254957dfdda819337e1",
      "a932a12a465949d992e5908c9fb20439",
      "78e8e43798104b9a904092ac64605f1f",
      "ba814c92135e4266b06abef1414a0991",
      "ae36771519ae4c9a86b8c347955aa1be",
      "d6d9fee197234676a685f8b18fd9d970",
      "7bbb11608f4846ecb970902c3a741231",
      "16539b65c83b429fb4bfc422eee6a461",
      "560a02a6e8ad49b6a77bb86000702872",
      "dbe611a7a8e24be98254d21cbfc07b29",
      "95e469dd64f345e1877c4e78f0dad725",
      "6c776739fb824b7ab0a9fbec2655d64b",
      "8a304c7992914645be8da6062420fa43",
      "6b8994c588b543e68f5c22408fa55ef1",
      "9033f83bf75e494f9ff9ce99a5cc54c6",
      "f96c725c6d0f45bc9f9d8b5a804c4c04",
      "75355478403348ec9e82de27d3151770",
      "05d410e1ae694020ab7beb7ab675c222",
      "524a761240d241b8b55237e771869a59"
     ]
    },
    "id": "d1GwkvVswQhT",
    "outputId": "dc5f9275-3128-4f41-9589-7301a13c9861"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a249604a45643c0b76b113d9e1c4a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a33d73668c4a4f853c24dca53090d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a4e979bc1e4186bd19c0ef868662c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8c6f823c474a1a852d17a8a523630f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560a02a6e8ad49b6a77bb86000702872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "\n",
    "# create tokenize function\n",
    "def tokenize_function(examples):\n",
    "    text = examples[\"text\"]\n",
    "\n",
    "    # tokenize and truncate the text if it is too long\n",
    "    tokenizer.truncation_side = 'left'\n",
    "    tokenized_inputs = tokenizer(text, return_tensors='np', truncation=True, max_length=512)\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "# add pad token if None exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# tokenize the training and validation sets\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FCvPzPF9wT59"
   },
   "outputs": [],
   "source": [
    "# create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "f105079e4b22435ab8535eb95f39f7a3",
      "beeab320570d4e1a888544d083dc067b",
      "14fae2df25214b1a9ff78ebe714feae4",
      "f0cb05fb7d3c4b4a9e5eeb81c47784d0",
      "bec043e84315446ca732e03443fbb33d",
      "1ff961a70b2c44448b639126df235810",
      "6c9fc8e216c24707b306ba3dfde6c8c4",
      "8d8a4c4112144292a6e6a23a369bdda8",
      "f09b70d4c7774946b0ef900d52476e37",
      "5a4d2b0c306248119a6b283e11dfb492",
      "947c180d2d5c42da849a7408d159fb50",
      "c26068dab03b4ce38e9fc1a4d256caf5",
      "bff7aae18b7e42848ed2ef675b902e69",
      "a8f28622680845e292192377373b7460",
      "df932d2bfd61491a8f1b1b278859c40e",
      "257d2b76ca9e4e5eaede7342c1800822",
      "e04a856d470f44eb87d78b3bd06353cb",
      "90db8161f7ff49bdb1d049f68a90beb3",
      "093a6bc2f6934ef191cb4a5d976b1691",
      "0dc0d54320e641e9ba8ed4b48587f7ca",
      "943ab90b1d974f9692a8d843460bf70d",
      "0c56107146a046bf8c770c7d74be62ed",
      "5a1d0f45897643a5a18e499ec5a08760",
      "3079302874b64940b97019c4f4c07122",
      "2f25c2888dcc4dc19e625e3f7c21126b",
      "bce852156ad1460087a10a5b89b6d993",
      "16096a140d0f48079c1eeb0122ebf433",
      "5e40753fdefe4ecc843442c26bc5d80c",
      "2039dd6c978148d0b05dc7efc479687b",
      "a3defd31fd2f4db2bc511496d3e828a6",
      "2405f04fba11449393538a069a563bf9",
      "1414ef533bc24edfa98b9eedf9ede1c9",
      "c1fdee9843904770bd476d8552f486aa",
      "597374d328e245d3b52d6ee4d19f3ae9",
      "f96da23b7dd0461e8aa9af15e6a396ac",
      "92612c5063be47249c74506ae0b6e9d8",
      "d2c260bd1b5e47e3a925866477fc371b",
      "ac7d01b06cc44e4abc9d9e59bef83fca",
      "205c13ad57284eba8148352a2d8c4569",
      "d50d2b65b9b047cba2e33080d1f8d15f",
      "2643aa61051d44799f681fe56140038e",
      "96bf482ef5c5473cba6adffd49614c4d",
      "2d24f00455204985b66aa79d8b14f79f",
      "127b2c5941544ea2a9947df04f5b5ae7"
     ]
    },
    "id": "JOKTIeCEwYsN",
    "outputId": "7657ec1a-5e95-4797-8720-ae06ee9c307e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f105079e4b22435ab8535eb95f39f7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26068dab03b4ce38e9fc1a4d256caf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1d0f45897643a5a18e499ec5a08760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597374d328e245d3b52d6ee4d19f3ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "# define evaluation function to pass into trainer later\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    # Use argmax for other metrics that require class predictions\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels),\n",
    "        \"precision\": precision.compute(predictions=predictions, references=labels),\n",
    "        \"recall\": recall.compute(predictions=predictions, references=labels),\n",
    "        \"f1\": f1.compute(predictions=predictions, references=labels)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fadRtuc2wbd1",
    "outputId": "687b4751-be6e-471e-bb2c-a9a853d500de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions:\n",
      "---------------------------\n",
      "It was good. - Negative\n",
      "Not a fan, don't recommend. - Negative\n",
      "Better than the first one. - Negative\n",
      "This is not worth watching even once. - Negative\n",
      "This one is a pass. - Negative\n"
     ]
    }
   ],
   "source": [
    "# Untrained model predictions/performance\n",
    "\n",
    "text_list = [\"It was good.\", \"Not a fan, don't recommend.\",\n",
    "             \"Better than the first one.\", \"This is not worth watching even once.\",\n",
    "             \"This one is a pass.\"]\n",
    "\n",
    "print(\"Untrained model predictions:\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Get the device of the model\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "for text in text_list:\n",
    "    # tokenize the text and move to the same device as the model\n",
    "    inputs = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "    # compute logits\n",
    "    logits =  model(inputs).logits\n",
    "    # convert logits to labels\n",
    "    predictions = torch.argmax(logits)\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OgoP3dwuwfNY"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type='SEQ_CLS', # sequence classification\n",
    "                         r = 4, # intrinsic rank of trainable weight matrix\n",
    "                         lora_alpha=32,  # this is like learning rate\n",
    "                         lora_dropout=0.01, # probability of dropout\n",
    "                         target_modules=['q_lin'])  # we apply lora to query layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGNvSTwswiUn",
    "outputId": "30acc25b-7b5e-47e5-b5e3-034106d694a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kFTO9Y9Nwk4K"
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-4\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "\n",
    "# define training arguments\n",
    "training_args = TrainingArguments(output_dir=model_checkpoint + '-lora-text-classification',\n",
    "                learning_rate=lr,\n",
    "                per_device_train_batch_size=batch_size,\n",
    "                per_device_eval_batch_size=batch_size,\n",
    "                num_train_epochs=num_epochs,\n",
    "                weight_decay=0.01,\n",
    "                eval_strategy='epoch',\n",
    "                save_strategy='epoch',\n",
    "                load_best_model_at_end=True,\n",
    "                report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "Dc1j5PzwwwTs",
    "outputId": "e56cbf13-e841-4fa1-d439-1507b8af0016"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-11-1062403234.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, args=training_args, data_collator=data_collator,\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 08:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.397471</td>\n",
       "      <td>{'accuracy': 0.869}</td>\n",
       "      <td>{'precision': 0.8448598130841122}</td>\n",
       "      <td>{'recall': 0.904}</td>\n",
       "      <td>{'f1': 0.8734299516908213}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266523</td>\n",
       "      <td>{'accuracy': 0.893}</td>\n",
       "      <td>{'precision': 0.9337748344370861}</td>\n",
       "      <td>{'recall': 0.846}</td>\n",
       "      <td>{'f1': 0.887722980062959}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260335</td>\n",
       "      <td>{'accuracy': 0.898}</td>\n",
       "      <td>{'precision': 0.9180672268907563}</td>\n",
       "      <td>{'recall': 0.874}</td>\n",
       "      <td>{'f1': 0.8954918032786885}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.262262</td>\n",
       "      <td>{'accuracy': 0.904}</td>\n",
       "      <td>{'precision': 0.9105691056910569}</td>\n",
       "      <td>{'recall': 0.896}</td>\n",
       "      <td>{'f1': 0.9032258064516129}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.288784</td>\n",
       "      <td>{'accuracy': 0.9}</td>\n",
       "      <td>{'precision': 0.9310344827586207}</td>\n",
       "      <td>{'recall': 0.864}</td>\n",
       "      <td>{'f1': 0.8962655601659751}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>{'accuracy': 0.904}</td>\n",
       "      <td>{'precision': 0.9105691056910569}</td>\n",
       "      <td>{'recall': 0.896}</td>\n",
       "      <td>{'f1': 0.9032258064516129}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.282606</td>\n",
       "      <td>{'accuracy': 0.907}</td>\n",
       "      <td>{'precision': 0.9213250517598344}</td>\n",
       "      <td>{'recall': 0.89}</td>\n",
       "      <td>{'f1': 0.9053916581892166}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.287620</td>\n",
       "      <td>{'accuracy': 0.908}</td>\n",
       "      <td>{'precision': 0.908}</td>\n",
       "      <td>{'recall': 0.908}</td>\n",
       "      <td>{'f1': 0.908}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.293282</td>\n",
       "      <td>{'accuracy': 0.908}</td>\n",
       "      <td>{'precision': 0.9146341463414634}</td>\n",
       "      <td>{'recall': 0.9}</td>\n",
       "      <td>{'f1': 0.907258064516129}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.294446</td>\n",
       "      <td>{'accuracy': 0.908}</td>\n",
       "      <td>{'precision': 0.9163265306122449}</td>\n",
       "      <td>{'recall': 0.898}</td>\n",
       "      <td>{'f1': 0.907070707070707}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=0.2833731811523437, metrics={'train_runtime': 502.9787, 'train_samples_per_second': 19.882, 'train_steps_per_second': 2.485, 'total_flos': 1253694805157184.0, 'train_loss': 0.2833731811523437, 'epoch': 10.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create trainer object\n",
    "trainer = Trainer(model=model, args=training_args, data_collator=data_collator,\n",
    "                  train_dataset=tokenized_dataset['train'], eval_dataset=tokenized_dataset['validation'],\n",
    "                  tokenizer = tokenizer, compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wer4_1Cyu3X",
    "outputId": "64b2d217-26f9-45a6-9f55-04009a533410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "-------------------------\n",
      "It was good. - Positive\n",
      "Not a fan, don't recommend. - Negative\n",
      "Better than the first one. - Positive\n",
      "This is not worth watching even once. - Negative\n",
      "This one is a pass. - Negative\n"
     ]
    }
   ],
   "source": [
    "print(\"Trained model predictions:\")\n",
    "print(\"-------------------------\")\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "for text in text_list:\n",
    "    # tokenize the text\n",
    "    inputs = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "    # compute logits\n",
    "    logits =  model(inputs).logits\n",
    "    # convert logits to labels\n",
    "    predictions = torch.argmax(logits, 1)\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
